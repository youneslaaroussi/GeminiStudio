# GeminiStudio - Single VM Deployment
# This Terraform configuration creates a GCE VM with Docker to run all backend services

terraform {
  required_version = ">= 1.0"
  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}

# Static external IP for the VM
resource "google_compute_address" "gemini_studio" {
  name   = "gemini-studio-ip"
  region = var.region
}

# Firewall rule - only SSH and HTTP/HTTPS (backend services are internal-only)
resource "google_compute_firewall" "gemini_studio" {
  name    = "gemini-studio-firewall"
  network = "default"

  allow {
    protocol = "tcp"
    ports    = ["22", "80", "443"]
  }

  source_ranges = ["0.0.0.0/0"]
  target_tags   = ["gemini-studio"]
}

# Generated .env file content
locals {
  env_file_content = <<-ENVFILE
# Auto-generated by Terraform - do not edit manually
# Re-run 'terraform apply' to update

# Google Cloud Configuration
GOOGLE_PROJECT_ID=${var.project_id}
ASSET_GCS_BUCKET=${var.gcs_bucket_name}
CHECKPOINT_GCS_BUCKET=${var.gcs_bucket_name}
SPEECH_GCS_BUCKET=${var.gcs_bucket_name}

# API Keys
GEMINI_API_KEY=${local.gemini_api_key}
REPLICATE_API_TOKEN=${local.replicate_api_token}
STRIPE_SECRET_KEY=${local.stripe_secret_key}

# Algolia (optional)
ALGOLIA_APP_ID=${var.algolia_app_id}
ALGOLIA_ADMIN_API_KEY=${local.algolia_admin_key}
ALGOLIA_INDEX_PREFIX=${var.algolia_index_prefix}

# Pub/Sub Topics
PIPELINE_EVENT_TOPIC=gemini-pipeline-events
RENDER_EVENT_TOPIC=gemini-render-events
VEO_EVENT_TOPIC=gemini-veo-events

# Service Configuration
GEMINI_MODEL_ID=${var.gemini_model_id}
VEO_LOCATION=${var.veo_location}
VEO_MODEL_ID=${var.veo_model_id}
SPEECH_LOCATION=${var.speech_location}
SPEECH_MODEL=${var.speech_model}
SPEECH_LANGUAGE_CODES=${var.speech_language_codes}

# Renderer
RENDERER_CONCURRENCY=${var.renderer_concurrency}
RENDERER_HEADLESS_CONCURRENCY=${var.renderer_concurrency}
RENDERER_TASK_TIMEOUT_MS=600000
LOG_LEVEL=info

# Frontend URL (update after deploying frontend)
FRONTEND_URL=${var.frontend_url}
CORS_ORIGIN=${var.frontend_url}

# Debug
DEBUG=false

# Firebase Configuration
NEXT_PUBLIC_FIREBASE_API_KEY=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_api_key[0].secret_data, "") : ""}
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_auth_domain[0].secret_data, "") : ""}
NEXT_PUBLIC_FIREBASE_PROJECT_ID=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_project_id[0].secret_data, "") : ""}
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_storage_bucket[0].secret_data, "") : ""}
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_messaging_sender_id[0].secret_data, "") : ""}
NEXT_PUBLIC_FIREBASE_APP_ID=${var.use_secret_manager ? try(data.google_secret_manager_secret_version.firebase_app_id[0].secret_data, "") : ""}
FIREBASE_DATABASE_URL=${local.firebase_database_url}

# HMAC Shared Secrets
ASSET_SERVICE_SHARED_SECRET=${local.asset_service_shared_secret}
RENDERER_SHARED_SECRET=${local.renderer_shared_secret}
ENVFILE

  # Startup script to install Docker, clone repo, and configure environment
  startup_script = <<-EOF
    #!/bin/bash
    set -e

    # Install Docker
    apt-get update
    apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release git

    curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null

    apt-get update
    apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

    # Enable and start Docker
    systemctl enable docker
    systemctl start docker

    # Add default user to docker group
    usermod -aG docker $(ls /home | head -1) || true

    # Create app directory structure
    mkdir -p /opt/gemini-studio/deploy/secrets
    chown -R 1000:1000 /opt/gemini-studio

    echo "Docker installation complete!"
    echo "Clone your repo to /opt/gemini-studio and run: docker compose up -d"
  EOF
}

# GCE VM Instance
resource "google_compute_instance" "gemini_studio" {
  name         = var.instance_name
  machine_type = var.machine_type
  zone         = var.zone

  tags = ["gemini-studio"]

  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-12"
      size  = var.disk_size_gb
      type  = "pd-balanced"
    }
  }

  network_interface {
    network = "default"
    access_config {
      nat_ip = google_compute_address.gemini_studio.address
    }
  }

  metadata = {
    startup-script = local.startup_script
  }

  # Allow stopping for updates
  allow_stopping_for_update = true

  # Service account with required permissions
  service_account {
    email  = var.service_account_email != "" ? var.service_account_email : null
    scopes = ["cloud-platform"]
  }

  labels = {
    app         = "gemini-studio"
    environment = "staging"
  }
}

# Optional: Cloud Storage bucket for assets (if not already exists)
resource "google_storage_bucket" "assets" {
  count = var.create_gcs_bucket ? 1 : 0

  name          = var.gcs_bucket_name
  location      = var.region
  force_destroy = true  # Allow deletion even with objects

  uniform_bucket_level_access = true

  cors {
    origin          = ["*"]
    method          = ["GET", "HEAD", "PUT", "POST", "DELETE"]
    response_header = ["*"]
    max_age_seconds = 3600
  }
}

# Pub/Sub topics - uses data sources if they exist, creates if they don't
# Import existing topics with: terraform import google_pubsub_topic.pipeline_events projects/PROJECT_ID/topics/gemini-pipeline-events

resource "google_pubsub_topic" "pipeline_events" {
  count   = var.create_pubsub_topics ? 1 : 0
  name    = "gemini-pipeline-events"
  project = var.project_id

  lifecycle {
    # If topic already exists, import it first or set create_pubsub_topics = false
    prevent_destroy = false
    # Ignore changes if topic was created outside Terraform
    ignore_changes = [labels]
  }
}

resource "google_pubsub_topic" "render_events" {
  count   = var.create_pubsub_topics ? 1 : 0
  name    = "gemini-render-events"
  project = var.project_id

  lifecycle {
    prevent_destroy = false
    ignore_changes  = [labels]
  }
}

resource "google_pubsub_topic" "veo_events" {
  count   = var.create_pubsub_topics ? 1 : 0
  name    = "gemini-veo-events"
  project = var.project_id

  lifecycle {
    prevent_destroy = false
    ignore_changes  = [labels]
  }
}

# Generate .env file locally (to be copied to VM)
resource "local_file" "env_file" {
  content  = local.env_file_content
  filename = "${path.module}/../generated.env"

  # Make it readable only by owner (contains secrets)
  file_permission = "0600"
}
