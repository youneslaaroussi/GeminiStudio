{
  "generatedAt": "2026-02-04T03:47:52.178Z",
  "tools": {
    "captureAsset": {
      "name": "captureAsset",
      "label": "Capture Asset",
      "description": "Bookmark a timeline moment for an uploaded asset using its asset ID and capture an exact still.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false,
        "notes": "Requires browser APIs (canvas, video elements)"
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. asset_123",
          "required": true
        },
        {
          "name": "timecode",
          "label": "Time (seconds)",
          "type": "number",
          "placeholder": "12.4",
          "description": "Exact timeline position in seconds.",
          "required": true
        },
        {
          "name": "notes",
          "label": "Notes",
          "type": "textarea",
          "placeholder": "Optional context for the captured asset."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/captureAssetInput",
        "definitions": {
          "captureAssetInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "timecode": {
                "type": "number",
                "minimum": 0
              },
              "notes": {
                "type": "string"
              }
            },
            "required": [
              "assetId",
              "timecode"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "captureFaces": {
      "name": "captureFaces",
      "label": "Capture Faces",
      "description": "Capture frames from a video at face detection timestamps with bounding boxes drawn around detected faces.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false,
        "notes": "Requires browser APIs (canvas, video elements)"
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. asset_123",
          "required": true
        },
        {
          "name": "faceIndex",
          "label": "Face Index (optional)",
          "type": "number",
          "placeholder": "Leave empty for all faces",
          "description": "Capture a specific face by index (0-based). Leave empty to capture all faces."
        },
        {
          "name": "notes",
          "label": "Notes",
          "type": "textarea",
          "placeholder": "Optional context for the captured frames."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/captureFacesInput",
        "definitions": {
          "captureFacesInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "faceIndex": {
                "type": "number",
                "minimum": 0
              },
              "notes": {
                "type": "string"
              }
            },
            "required": [
              "assetId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "generateImage": {
      "name": "generateImage",
      "label": "Generate Image",
      "description": "Generate an image using Google's Gemini image model from a text prompt.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "generateImage"
      },
      "fields": [],
      "inputSchema": null
    },
    "generateMusic": {
      "name": "generateMusic",
      "label": "Generate Music (Lyria)",
      "description": "Generate original music using Google's Lyria AI model. Creates music from a text description including genre, mood, instruments, and tempo.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "generateMusic"
      },
      "fields": [
        {
          "name": "prompt",
          "label": "Music Description",
          "type": "textarea",
          "placeholder": "Upbeat electronic dance music with synth leads, driving bassline, 128 BPM, energetic festival vibe...",
          "description": "Describe the music you want: genre, mood, instruments, tempo, style.",
          "required": true
        },
        {
          "name": "durationSeconds",
          "label": "Duration",
          "type": "select",
          "options": [
            {
              "value": "10",
              "label": "10 seconds"
            },
            {
              "value": "20",
              "label": "20 seconds"
            },
            {
              "value": "30",
              "label": "30 seconds"
            },
            {
              "value": "60",
              "label": "60 seconds"
            }
          ],
          "defaultValue": "30",
          "description": "Length of the generated music."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/generateMusicInput",
        "definitions": {
          "generateMusicInput": {
            "type": "object",
            "properties": {
              "prompt": {
                "type": "string",
                "minLength": 5
              },
              "durationSeconds": {
                "anyOf": [
                  {
                    "type": "string",
                    "enum": [
                      "10",
                      "20",
                      "30",
                      "60"
                    ]
                  },
                  {
                    "type": "number"
                  }
                ],
                "default": "30"
              }
            },
            "required": [
              "prompt"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "generateSpeech": {
      "name": "generateSpeech",
      "label": "Generate Speech (TTS)",
      "description": "Generate natural-sounding speech from text using Google's TTS model. Great for voiceovers, narration, and accessibility.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "generateSpeech"
      },
      "fields": [
        {
          "name": "text",
          "label": "Text to Speak",
          "type": "textarea",
          "placeholder": "Enter the text you want to convert to speech...",
          "description": "The text to convert to speech (up to 5000 characters).",
          "required": true
        },
        {
          "name": "voice",
          "label": "Voice",
          "type": "select",
          "options": [
            {
              "value": "Puck",
              "label": "Puck - Upbeat, playful male"
            },
            {
              "value": "Charon",
              "label": "Charon - Deep, authoritative male"
            },
            {
              "value": "Kore",
              "label": "Kore - Warm, friendly female"
            },
            {
              "value": "Fenrir",
              "label": "Fenrir - Bold, energetic male"
            },
            {
              "value": "Aoede",
              "label": "Aoede - Bright, cheerful female"
            },
            {
              "value": "Leda",
              "label": "Leda - Calm, soothing female"
            },
            {
              "value": "Orus",
              "label": "Orus - Clear, professional male"
            },
            {
              "value": "Zephyr",
              "label": "Zephyr - Soft, gentle"
            }
          ],
          "defaultValue": "Kore",
          "description": "Choose the voice for the speech."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/generateSpeechInput",
        "definitions": {
          "generateSpeechInput": {
            "type": "object",
            "properties": {
              "text": {
                "type": "string",
                "minLength": 2,
                "maxLength": 5000
              },
              "voice": {
                "type": "string",
                "enum": [
                  "Puck",
                  "Charon",
                  "Kore",
                  "Fenrir",
                  "Aoede",
                  "Leda",
                  "Orus",
                  "Zephyr"
                ],
                "default": "Kore"
              }
            },
            "required": [
              "text"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "getAssetMetadata": {
      "name": "getAssetMetadata",
      "label": "Get Asset Metadata",
      "description": "Get detailed metadata for an asset including face detection, shot detection, labels, and transcription.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "getAssetMetadata"
      },
      "fields": [],
      "inputSchema": null
    },
    "listAssets": {
      "name": "listAssets",
      "label": "List Assets",
      "description": "Return the uploaded assets currently available in the Assets panel.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "listAssets"
      },
      "fields": [],
      "inputSchema": {
        "$ref": "#/definitions/listAssetsInput",
        "definitions": {
          "listAssetsInput": {
            "type": "object",
            "properties": {},
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "projectHistory": {
      "name": "projectHistory",
      "label": "Project History",
      "description": "Inspect the undo/redo history of the current project or trigger undo and redo operations.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false,
        "notes": "Requires browser APIs (canvas, video elements)"
      },
      "fields": [
        {
          "name": "action",
          "label": "Action",
          "type": "select",
          "description": "Choose whether to view history, undo, or redo.",
          "options": [
            {
              "value": "status",
              "label": "Show History Status"
            },
            {
              "value": "undo",
              "label": "Undo"
            },
            {
              "value": "redo",
              "label": "Redo"
            }
          ],
          "required": true,
          "defaultValue": "status"
        },
        {
          "name": "steps",
          "label": "Steps",
          "type": "number",
          "placeholder": "1",
          "description": "How many steps to undo or redo (defaults to 1). Ignored when showing status."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/projectHistoryInput",
        "definitions": {
          "projectHistoryInput": {
            "type": "object",
            "properties": {
              "action": {
                "type": "string",
                "enum": [
                  "status",
                  "undo",
                  "redo"
                ],
                "default": "status"
              },
              "steps": {
                "type": "integer",
                "minimum": 1,
                "maximum": 50
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineAddLayer": {
      "name": "timelineAddLayer",
      "label": "Add Timeline Layer",
      "description": "Create a new timeline layer using the existing project store helpers.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "type",
          "label": "Layer Type",
          "type": "select",
          "description": "Choose the media type this layer will hold.",
          "options": [
            {
              "value": "video",
              "label": "Video"
            },
            {
              "value": "audio",
              "label": "Audio"
            },
            {
              "value": "text",
              "label": "Text"
            },
            {
              "value": "image",
              "label": "Image"
            }
          ],
          "required": true
        },
        {
          "name": "name",
          "label": "Layer Name",
          "type": "text",
          "placeholder": "Optional custom name"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineAddLayerInput",
        "definitions": {
          "timelineAddLayerInput": {
            "type": "object",
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "video",
                  "audio",
                  "text",
                  "image"
                ]
              },
              "name": {
                "type": "string",
                "minLength": 1,
                "maxLength": 120
              }
            },
            "required": [
              "type"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineAddClip": {
      "name": "timelineAddClip",
      "label": "Add Timeline Clip",
      "description": "Insert a new clip on the timeline. For media clips (video/audio/image), provide type and assetId only—do not pass src (proxy URL is derived from assetId). For text clips, provide type='text' and text content. Use template, subtitle, backgroundColor for text styling. Use enterTransition and exitTransition for fade/slide/zoom in/out (type, duration 0.1-5s).",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "addClipToTimeline"
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "Asset ID from listAssets or generateImage",
          "description": "Required for media clips. Proxy URL is derived from assetId—do not pass src."
        },
        {
          "name": "type",
          "label": "Clip Type",
          "type": "select",
          "options": [
            {
              "value": "video",
              "label": "Video"
            },
            {
              "value": "audio",
              "label": "Audio"
            },
            {
              "value": "image",
              "label": "Image"
            },
            {
              "value": "text",
              "label": "Text"
            }
          ],
          "description": "Required for media clips. Optional if assetId is provided (will be inferred from asset)."
        },
        {
          "name": "layerId",
          "label": "Layer ID",
          "type": "text",
          "placeholder": "Optional layer ID (defaults to matching layer type)"
        },
        {
          "name": "name",
          "label": "Clip Name",
          "type": "text",
          "placeholder": "Friendly clip name"
        },
        {
          "name": "start",
          "label": "Start (seconds)",
          "type": "number",
          "description": "Defaults to 0 if not provided."
        },
        {
          "name": "duration",
          "label": "Duration (seconds)",
          "type": "number",
          "description": "Optional: defaults to asset duration or 5s for images."
        },
        {
          "name": "text",
          "label": "Text Content",
          "type": "textarea",
          "description": "Required for text clips."
        },
        {
          "name": "offset",
          "label": "Source Offset",
          "type": "number",
          "description": "Trim the beginning of the source by this many seconds."
        },
        {
          "name": "speed",
          "label": "Playback Speed",
          "type": "number",
          "description": "Playback speed multiplier (defaults to 1)."
        },
        {
          "name": "position",
          "label": "Position",
          "type": "json",
          "placeholder": "{\"x\":0,\"y\":0}",
          "description": "Scene position as { x, y } in pixels."
        },
        {
          "name": "scale",
          "label": "Scale",
          "type": "json",
          "placeholder": "{\"x\":1,\"y\":1}",
          "description": "Scale multiplier as { x, y }."
        },
        {
          "name": "width",
          "label": "Width",
          "type": "number",
          "description": "Optional intrinsic media width (video/image)."
        },
        {
          "name": "height",
          "label": "Height",
          "type": "number",
          "description": "Optional intrinsic media height (video/image)."
        },
        {
          "name": "objectFit",
          "label": "Object Fit",
          "type": "select",
          "description": "Video object-fit behavior.",
          "options": [
            {
              "value": "contain",
              "label": "Contain"
            },
            {
              "value": "cover",
              "label": "Cover"
            },
            {
              "value": "fill",
              "label": "Fill"
            }
          ]
        },
        {
          "name": "focus",
          "label": "Focus / Zoom",
          "type": "json",
          "placeholder": "{\"x\":0.5,\"y\":0.5,\"zoom\":1}",
          "description": "Optional video focus: center (x,y 0–1) and zoom ratio (1 = full frame, 2 = 2×)."
        },
        {
          "name": "volume",
          "label": "Volume",
          "type": "number",
          "description": "Audio volume (0-1)."
        },
        {
          "name": "fontSize",
          "label": "Font Size",
          "type": "number",
          "description": "Text clip font size in pixels."
        },
        {
          "name": "fill",
          "label": "Fill Color",
          "type": "text",
          "placeholder": "#ffffff"
        },
        {
          "name": "opacity",
          "label": "Opacity",
          "type": "number",
          "description": "Text opacity (0-1)."
        },
        {
          "name": "template",
          "label": "Text Template",
          "type": "select",
          "description": "Template style: text (default), title-card, lower-third, caption-style.",
          "options": [
            {
              "value": "text",
              "label": "Plain Text"
            },
            {
              "value": "title-card",
              "label": "Title Card"
            },
            {
              "value": "lower-third",
              "label": "Lower Third"
            },
            {
              "value": "caption-style",
              "label": "Caption Style"
            }
          ]
        },
        {
          "name": "subtitle",
          "label": "Subtitle",
          "type": "text",
          "description": "For title-card and lower-third templates."
        },
        {
          "name": "backgroundColor",
          "label": "Background Color",
          "type": "text",
          "placeholder": "rgba(0,0,0,0.8) or #1a1a2e",
          "description": "For templates with backgrounds."
        },
        {
          "name": "enterTransition",
          "label": "Enter Transition",
          "type": "json",
          "placeholder": "{\"type\":\"fade\",\"duration\":0.5}",
          "description": "In transition when clip starts. Type: fade, slide-left, slide-right, slide-up, slide-down, zoom, dip-to-black. Duration 0.1-5s."
        },
        {
          "name": "exitTransition",
          "label": "Exit Transition",
          "type": "json",
          "placeholder": "{\"type\":\"fade\",\"duration\":0.5}",
          "description": "Out transition when clip ends. Same types as enter."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineAddClipInput",
        "definitions": {
          "timelineAddClipInput": {
            "type": "object",
            "properties": {
              "layerId": {
                "type": "string"
              },
              "name": {
                "type": "string",
                "minLength": 1,
                "maxLength": 180
              },
              "start": {
                "type": "number",
                "minimum": 0,
                "default": 0
              },
              "duration": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "offset": {
                "type": "number",
                "minimum": 0
              },
              "speed": {
                "type": "number",
                "exclusiveMinimum": 0,
                "maximum": 8
              },
              "position": {
                "type": "object",
                "properties": {
                  "x": {
                    "type": "number"
                  },
                  "y": {
                    "type": "number"
                  }
                },
                "required": [
                  "x",
                  "y"
                ],
                "additionalProperties": false
              },
              "scale": {
                "$ref": "#/definitions/timelineAddClipInput/properties/position"
              },
              "assetId": {
                "type": "string"
              },
              "type": {
                "type": "string",
                "enum": [
                  "video",
                  "audio",
                  "image",
                  "text"
                ]
              },
              "width": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "height": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "sourceDuration": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "focus": {
                "type": "object",
                "properties": {
                  "x": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1
                  },
                  "y": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1
                  },
                  "zoom": {
                    "type": "number",
                    "minimum": 1
                  }
                },
                "required": [
                  "x",
                  "y",
                  "zoom"
                ],
                "additionalProperties": false
              },
              "objectFit": {
                "type": "string",
                "enum": [
                  "contain",
                  "cover",
                  "fill"
                ]
              },
              "volume": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "text": {
                "type": "string"
              },
              "fontSize": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "fill": {
                "type": "string"
              },
              "opacity": {
                "type": "number",
                "minimum": 0,
                "maximum": 1
              },
              "template": {
                "type": "string",
                "enum": [
                  "text",
                  "title-card",
                  "lower-third",
                  "caption-style"
                ]
              },
              "subtitle": {
                "type": "string"
              },
              "backgroundColor": {
                "type": "string"
              },
              "enterTransition": {
                "type": "object",
                "properties": {
                  "type": {
                    "type": "string",
                    "enum": [
                      "none",
                      "fade",
                      "slide-left",
                      "slide-right",
                      "slide-up",
                      "slide-down",
                      "cross-dissolve",
                      "zoom",
                      "blur",
                      "dip-to-black"
                    ]
                  },
                  "duration": {
                    "type": "number",
                    "minimum": 0.1,
                    "maximum": 5
                  }
                },
                "required": [
                  "type",
                  "duration"
                ],
                "additionalProperties": false
              },
              "exitTransition": {
                "$ref": "#/definitions/timelineAddClipInput/properties/enterTransition"
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineSplitClip": {
      "name": "timelineSplitClip",
      "label": "Split Timeline Clip",
      "description": "Split an existing clip using the project store's split action to preserve history.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "clipId",
          "label": "Clip ID",
          "type": "text",
          "required": true
        },
        {
          "name": "time",
          "label": "Split Time (seconds)",
          "type": "number",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineSplitClipInput",
        "definitions": {
          "timelineSplitClipInput": {
            "type": "object",
            "properties": {
              "clipId": {
                "type": "string",
                "minLength": 1
              },
              "time": {
                "type": "number",
                "minimum": 0,
                "description": "Timeline timestamp in seconds"
              }
            },
            "required": [
              "clipId",
              "time"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineUpdateClip": {
      "name": "timelineUpdateClip",
      "label": "Update Timeline Clip",
      "description": "Adjust clip timing and type-specific settings. For text clips, use textSettings with template, subtitle, backgroundColor. Use enterTransition and exitTransition to set fade/slide/zoom in/out effects (type, duration 0.1-5s).",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "updateClipInTimeline"
      },
      "fields": [
        {
          "name": "clipId",
          "label": "Clip ID",
          "type": "text",
          "required": true
        },
        {
          "name": "name",
          "label": "Clip Name",
          "type": "text",
          "placeholder": "Optional new name"
        },
        {
          "name": "start",
          "label": "Start (seconds)",
          "type": "number"
        },
        {
          "name": "duration",
          "label": "Duration (seconds)",
          "type": "number"
        },
        {
          "name": "offset",
          "label": "Source Offset",
          "type": "number"
        },
        {
          "name": "speed",
          "label": "Playback Speed",
          "type": "number"
        },
        {
          "name": "position",
          "label": "Position",
          "type": "json",
          "placeholder": "{\"x\":0,\"y\":0}"
        },
        {
          "name": "scale",
          "label": "Scale",
          "type": "json",
          "placeholder": "{\"x\":1,\"y\":1}"
        },
        {
          "name": "videoSettings",
          "label": "Video Settings",
          "type": "json",
          "placeholder": "{\"width\":1920,\"height\":1080,\"objectFit\":\"contain\",\"focus\":{\"x\":0.5,\"y\":0.5,\"zoom\":1},\"colorGrading\":{...},\"chromaKey\":{...}}",
          "description": "Do not pass src—media URL is derived from clip's assetId. focus: center (x,y 0–1) and zoom (1 = full frame, 2 = 2×). colorGrading: exposure only is -2 to 2; contrast, saturation, temperature, tint, highlights, shadows are -100 to 100 (use e.g. 20 or -30 for visible change—values like 1.4 are too small). chromaKey: key color (hex), threshold and smoothness 0–1 for green screen."
        },
        {
          "name": "audioSettings",
          "label": "Audio Settings",
          "type": "json",
          "placeholder": "{\"volume\":1}",
          "description": "Do not pass src—media URL is derived from clip's assetId."
        },
        {
          "name": "imageSettings",
          "label": "Image Settings",
          "type": "json",
          "placeholder": "{\"width\":1920,\"height\":1080}",
          "description": "Do not pass src—media URL is derived from clip's assetId. colorGrading: exposure -2 to 2; contrast, saturation, temperature, tint, highlights, shadows -100 to 100 (use e.g. 20 or -30, not 1.4)."
        },
        {
          "name": "textSettings",
          "label": "Text Settings",
          "type": "json",
          "placeholder": "{\"text\":\"\",\"fontSize\":48,\"fill\":\"#ffffff\",\"opacity\":1,\"template\":\"lower-third\",\"subtitle\":\"\",\"backgroundColor\":\"rgba(0,0,0,0.8)\"}",
          "description": "For text clips: template (text|title-card|lower-third|caption-style), subtitle, backgroundColor."
        },
        {
          "name": "enterTransition",
          "label": "Enter Transition",
          "type": "json",
          "placeholder": "{\"type\":\"fade\",\"duration\":0.5}",
          "description": "In transition when clip starts. Type: fade, slide-left, slide-right, slide-up, slide-down, zoom, dip-to-black. Duration 0.1-5s. Omit or type:none to clear."
        },
        {
          "name": "exitTransition",
          "label": "Exit Transition",
          "type": "json",
          "placeholder": "{\"type\":\"fade\",\"duration\":0.5}",
          "description": "Out transition when clip ends. Same types as enter. Omit or type:none to clear."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineUpdateClipInput",
        "definitions": {
          "timelineUpdateClipInput": {
            "type": "object",
            "properties": {
              "clipId": {
                "type": "string",
                "minLength": 1
              },
              "name": {
                "type": "string",
                "minLength": 1,
                "maxLength": 180
              },
              "start": {
                "type": "number",
                "minimum": 0
              },
              "duration": {
                "type": "number",
                "exclusiveMinimum": 0
              },
              "offset": {
                "type": "number",
                "minimum": 0
              },
              "speed": {
                "type": "number",
                "exclusiveMinimum": 0,
                "maximum": 8
              },
              "position": {
                "type": "object",
                "properties": {
                  "x": {
                    "type": "number"
                  },
                  "y": {
                    "type": "number"
                  }
                },
                "required": [
                  "x",
                  "y"
                ],
                "additionalProperties": false
              },
              "scale": {
                "$ref": "#/definitions/timelineUpdateClipInput/properties/position"
              },
              "assetId": {
                "type": "string"
              },
              "videoSettings": {
                "type": "object",
                "properties": {
                  "width": {
                    "type": "number",
                    "exclusiveMinimum": 0
                  },
                  "height": {
                    "type": "number",
                    "exclusiveMinimum": 0
                  },
                  "objectFit": {
                    "type": "string",
                    "enum": [
                      "contain",
                      "cover",
                      "fill"
                    ]
                  },
                  "focus": {
                    "type": "object",
                    "properties": {
                      "x": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1
                      },
                      "y": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1
                      },
                      "zoom": {
                        "type": "number",
                        "minimum": 1
                      }
                    },
                    "required": [
                      "x",
                      "y",
                      "zoom"
                    ],
                    "additionalProperties": false
                  },
                  "colorGrading": {
                    "type": "object",
                    "description": "Exposure: -2 to 2. All others (contrast, saturation, temperature, tint, highlights, shadows): -100 to 100. Use values like 20 or -30 for visible effect; values like 1.4 are too small.",
                    "properties": {
                      "exposure": {
                        "type": "number",
                        "minimum": -2,
                        "maximum": 2,
                        "description": "Range -2 to 2 (only field that uses this scale)."
                      },
                      "contrast": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100. Use ~20–50 for visible change."
                      },
                      "saturation": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100. Use ~20–50 for visible change."
                      },
                      "temperature": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100 (cool to warm). Use ~20–50 for visible change."
                      },
                      "tint": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100 (green to magenta). Use ~20–50 for visible change."
                      },
                      "highlights": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100. Use ~20–50 for visible change."
                      },
                      "shadows": {
                        "type": "number",
                        "minimum": -100,
                        "maximum": 100,
                        "description": "Range -100 to 100. Use ~20–50 for visible change."
                      }
                    },
                    "additionalProperties": false
                  },
                  "chromaKey": {
                    "type": "object",
                    "properties": {
                      "color": {
                        "type": "string",
                        "pattern": "^#[0-9a-fA-F]{3,6}$"
                      },
                      "threshold": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1
                      },
                      "smoothness": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1
                      }
                    },
                    "required": [
                      "color",
                      "threshold"
                    ],
                    "additionalProperties": false
                  }
                },
                "additionalProperties": false
              },
              "audioSettings": {
                "type": "object",
                "properties": {
                  "volume": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1
                  }
                },
                "additionalProperties": false
              },
              "imageSettings": {
                "type": "object",
                "properties": {
                  "width": {
                    "type": "number",
                    "exclusiveMinimum": 0
                  },
                  "height": {
                    "type": "number",
                    "exclusiveMinimum": 0
                  },
                  "colorGrading": {
                    "$ref": "#/definitions/timelineUpdateClipInput/properties/videoSettings/properties/colorGrading"
                  }
                },
                "additionalProperties": false
              },
              "textSettings": {
                "type": "object",
                "properties": {
                  "text": {
                    "type": "string",
                    "minLength": 1
                  },
                  "fontSize": {
                    "type": "number",
                    "exclusiveMinimum": 0
                  },
                  "fill": {
                    "type": "string"
                  },
                  "opacity": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1
                  },
                  "template": {
                    "type": "string",
                    "enum": [
                      "text",
                      "title-card",
                      "lower-third",
                      "caption-style"
                    ]
                  },
                  "subtitle": {
                    "type": "string"
                  },
                  "backgroundColor": {
                    "type": "string"
                  }
                },
                "additionalProperties": false
              },
              "enterTransition": {
                "anyOf": [
                  {
                    "anyOf": [
                      {
                        "not": {}
                      },
                      {
                        "type": "object",
                        "properties": {
                          "type": {
                            "type": "string",
                            "enum": [
                              "none",
                              "fade",
                              "slide-left",
                              "slide-right",
                              "slide-up",
                              "slide-down",
                              "cross-dissolve",
                              "zoom",
                              "blur",
                              "dip-to-black"
                            ]
                          },
                          "duration": {
                            "type": "number",
                            "minimum": 0.1,
                            "maximum": 5
                          }
                        },
                        "required": [
                          "type",
                          "duration"
                        ],
                        "additionalProperties": false
                      }
                    ]
                  },
                  {
                    "type": "null"
                  }
                ]
              },
              "exitTransition": {
                "anyOf": [
                  {
                    "anyOf": [
                      {
                        "not": {}
                      },
                      {
                        "$ref": "#/definitions/timelineUpdateClipInput/properties/enterTransition/anyOf/0/anyOf/1"
                      }
                    ]
                  },
                  {
                    "type": "null"
                  }
                ]
              }
            },
            "required": [
              "clipId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineDeleteClip": {
      "name": "timelineDeleteClip",
      "label": "Delete Timeline Clip",
      "description": "Remove one or more clips from the timeline by their IDs.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "deleteClipFromTimeline"
      },
      "fields": [
        {
          "name": "clipIds",
          "label": "Clip IDs",
          "type": "json",
          "placeholder": "[\"clip-abc123\", \"clip-def456\"]",
          "description": "JSON array of clip IDs to delete",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineDeleteClipInput",
        "definitions": {
          "timelineDeleteClipInput": {
            "type": "object",
            "properties": {
              "clipIds": {
                "type": "array",
                "items": {
                  "type": "string",
                  "minLength": 1
                },
                "minItems": 1,
                "description": "List of clip IDs to delete from the timeline"
              }
            },
            "required": [
              "clipIds"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "getTimelineState": {
      "name": "getTimelineState",
      "label": "Get Timeline State",
      "description": "Get the current state of the project timeline including all layers and clips with their IDs, positions, and properties.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "getTimelineState"
      },
      "fields": [
        {
          "name": "includeClipDetails",
          "label": "Include Clip Details",
          "type": "select",
          "options": [
            {
              "value": "true",
              "label": "Yes"
            },
            {
              "value": "false",
              "label": "No (summary only)"
            }
          ],
          "defaultValue": "true",
          "description": "Whether to include detailed clip information"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/getTimelineStateInput",
        "definitions": {
          "getTimelineStateInput": {
            "type": "object",
            "properties": {
              "includeClipDetails": {
                "type": "boolean",
                "default": true,
                "description": "Whether to include detailed clip information"
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineAddTransition": {
      "name": "timelineAddTransition",
      "label": "Add Timeline Transition",
      "description": "Add a transition effect between two adjacent video clips on the same layer. Supports fade and slide transitions.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "fromClipId",
          "label": "From Clip ID",
          "type": "text",
          "placeholder": "ID of the first (left) clip",
          "required": true
        },
        {
          "name": "toClipId",
          "label": "To Clip ID",
          "type": "text",
          "placeholder": "ID of the second (right) clip",
          "required": true
        },
        {
          "name": "type",
          "label": "Transition Type",
          "type": "select",
          "options": [
            {
              "value": "fade",
              "label": "Fade"
            },
            {
              "value": "slide-left",
              "label": "Slide left"
            },
            {
              "value": "slide-right",
              "label": "Slide right"
            },
            {
              "value": "slide-up",
              "label": "Slide up"
            },
            {
              "value": "slide-down",
              "label": "Slide down"
            }
          ],
          "defaultValue": "fade",
          "description": "The transition effect to apply between clips."
        },
        {
          "name": "duration",
          "label": "Duration (seconds)",
          "type": "number",
          "placeholder": "0.5",
          "description": "How long the transition lasts (0.1 to 5 seconds)."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineAddTransitionInput",
        "definitions": {
          "timelineAddTransitionInput": {
            "type": "object",
            "properties": {
              "fromClipId": {
                "type": "string",
                "minLength": 1
              },
              "toClipId": {
                "type": "string",
                "minLength": 1
              },
              "type": {
                "type": "string",
                "enum": [
                  "fade",
                  "slide-left",
                  "slide-right",
                  "slide-up",
                  "slide-down"
                ],
                "default": "fade",
                "description": "Transition effect type"
              },
              "duration": {
                "type": "number",
                "exclusiveMinimum": 0,
                "maximum": 5,
                "default": 0.5,
                "description": "Transition duration in seconds"
              }
            },
            "required": [
              "fromClipId",
              "toClipId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "timelineRemoveTransition": {
      "name": "timelineRemoveTransition",
      "label": "Remove Timeline Transition",
      "description": "Remove an existing transition between two clips.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "fromClipId",
          "label": "From Clip ID",
          "type": "text",
          "placeholder": "ID of the first (left) clip",
          "required": true
        },
        {
          "name": "toClipId",
          "label": "To Clip ID",
          "type": "text",
          "placeholder": "ID of the second (right) clip",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/timelineRemoveTransitionInput",
        "definitions": {
          "timelineRemoveTransitionInput": {
            "type": "object",
            "properties": {
              "fromClipId": {
                "type": "string",
                "minLength": 1
              },
              "toClipId": {
                "type": "string",
                "minLength": 1
              }
            },
            "required": [
              "fromClipId",
              "toClipId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "videoEffectsList": {
      "name": "videoEffectsList",
      "label": "List Video Effects",
      "description": "Show the available video effect providers and their default parameters.",
      "runLocation": "server",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [],
      "inputSchema": {
        "$ref": "#/definitions/videoEffectsListInput",
        "definitions": {
          "videoEffectsListInput": {
            "type": "object",
            "properties": {},
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "videoEffectsRun": {
      "name": "videoEffectsRun",
      "label": "Start Video Effect",
      "description": "Kick off a video effect job (for example Replicate SAM-2) for a given asset, using the configured provider.",
      "runLocation": "server",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "asset_123",
          "required": true
        },
        {
          "name": "effectId",
          "label": "Effect",
          "type": "select",
          "options": [
            {
              "value": "replicate.meta.sam2-video",
              "label": "Segment Anything v2 (Video)"
            }
          ],
          "required": true,
          "defaultValue": "replicate.meta.sam2-video",
          "description": "Choose which video effect to apply."
        },
        {
          "name": "params",
          "label": "Effect Parameters",
          "type": "json",
          "placeholder": "{\"videoFps\": 25}",
          "description": "Optional JSON payload to override effect defaults. Leave empty to use defaults."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/videoEffectsRunInput",
        "definitions": {
          "videoEffectsRunInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "effectId": {
                "type": "string",
                "enum": [
                  "replicate.meta.sam2-video"
                ]
              },
              "params": {
                "anyOf": [
                  {
                    "type": "object",
                    "additionalProperties": {}
                  },
                  {
                    "type": "string",
                    "minLength": 1
                  }
                ]
              }
            },
            "required": [
              "assetId",
              "effectId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "videoEffectsJobStatus": {
      "name": "videoEffectsJobStatus",
      "label": "Check Video Effect Job",
      "description": "Retrieve the latest status for a video effect job.",
      "runLocation": "server",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "jobId",
          "label": "Job ID",
          "type": "text",
          "placeholder": "job_123",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/videoEffectsJobStatusInput",
        "definitions": {
          "videoEffectsJobStatusInput": {
            "type": "object",
            "properties": {
              "jobId": {
                "type": "string",
                "minLength": 1
              }
            },
            "required": [
              "jobId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "veoGenerate": {
      "name": "veoGenerate",
      "label": "Generate Veo Video",
      "description": "Generate a video using Google Veo 3. Returns a job ID that can be polled for completion.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "generateVeoVideo"
      },
      "fields": [
        {
          "name": "prompt",
          "label": "Prompt",
          "type": "textarea",
          "placeholder": "A cinematic shot of a mountain landscape at sunrise...",
          "description": "Describe the video you want to generate in detail.",
          "required": true
        },
        {
          "name": "durationSeconds",
          "label": "Duration",
          "type": "select",
          "options": [
            {
              "value": "4",
              "label": "4 seconds"
            },
            {
              "value": "6",
              "label": "6 seconds"
            },
            {
              "value": "8",
              "label": "8 seconds"
            }
          ],
          "defaultValue": "8",
          "description": "Video duration. Only 8s is available for 1080p and 4K."
        },
        {
          "name": "aspectRatio",
          "label": "Aspect Ratio",
          "type": "select",
          "options": [
            {
              "value": "16:9",
              "label": "16:9 Landscape"
            },
            {
              "value": "9:16",
              "label": "9:16 Portrait"
            }
          ],
          "defaultValue": "16:9"
        },
        {
          "name": "resolution",
          "label": "Resolution",
          "type": "select",
          "options": [
            {
              "value": "720p",
              "label": "720p"
            },
            {
              "value": "1080p",
              "label": "1080p"
            },
            {
              "value": "4k",
              "label": "4K"
            }
          ],
          "defaultValue": "720p",
          "description": "Higher resolutions cost more credits and require 8s duration."
        },
        {
          "name": "generateAudio",
          "label": "Generate Audio",
          "type": "select",
          "options": [
            {
              "value": "true",
              "label": "Yes"
            },
            {
              "value": "false",
              "label": "No"
            }
          ],
          "defaultValue": "true",
          "description": "Whether to generate audio with the video."
        },
        {
          "name": "negativePrompt",
          "label": "Negative Prompt",
          "type": "text",
          "placeholder": "blurry, low quality, text, watermark...",
          "description": "Optional: describe what to avoid in the generated video."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/veoGenerateInput",
        "definitions": {
          "veoGenerateInput": {
            "type": "object",
            "properties": {
              "prompt": {
                "type": "string",
                "minLength": 1
              },
              "durationSeconds": {
                "type": "number",
                "default": 8
              },
              "aspectRatio": {
                "type": "string",
                "enum": [
                  "16:9",
                  "9:16"
                ],
                "default": "16:9"
              },
              "resolution": {
                "type": "string",
                "enum": [
                  "720p",
                  "1080p",
                  "4k"
                ],
                "default": "720p"
              },
              "generateAudio": {
                "type": "boolean",
                "default": true
              },
              "negativePrompt": {
                "type": "string"
              }
            },
            "required": [
              "prompt"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "veoJobStatus": {
      "name": "veoJobStatus",
      "label": "Check Veo Job Status",
      "description": "Check the status of a Veo video generation job.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "jobId",
          "label": "Job ID",
          "type": "text",
          "placeholder": "veo_abc123...",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/veoJobStatusInput",
        "definitions": {
          "veoJobStatusInput": {
            "type": "object",
            "properties": {
              "jobId": {
                "type": "string",
                "minLength": 1
              }
            },
            "required": [
              "jobId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "digestAsset": {
      "name": "digestAsset",
      "label": "Digest Asset (Deprecated)",
      "description": "DEPRECATED: Use watchAsset instead for context-aware analysis. This tool analyzes media in isolation without conversation context. Only use this if you specifically need isolated analysis without considering prior discussion.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. asset_abc123",
          "description": "The ID of the asset to analyze.",
          "required": true
        },
        {
          "name": "query",
          "label": "Question (optional)",
          "type": "textarea",
          "placeholder": "What specific aspects would you like to know about?",
          "description": "Optional: Ask a specific question about the asset instead of getting a general analysis."
        },
        {
          "name": "depth",
          "label": "Analysis Depth",
          "type": "select",
          "options": [
            {
              "value": "quick",
              "label": "Quick (2-3 sentences)"
            },
            {
              "value": "detailed",
              "label": "Detailed (comprehensive analysis)"
            },
            {
              "value": "exhaustive",
              "label": "Exhaustive (scene-by-scene, every detail)"
            }
          ],
          "defaultValue": "detailed",
          "description": "How thorough should the analysis be?"
        },
        {
          "name": "startOffset",
          "label": "Start Time (optional)",
          "type": "text",
          "placeholder": "e.g. 30s or 1m30s",
          "description": "For videos only: analyze from this timestamp. Use when the user asks about a specific part of a video or to limit analysis to a segment. Format: 30s, 1m30s, 2m."
        },
        {
          "name": "endOffset",
          "label": "End Time (optional)",
          "type": "text",
          "placeholder": "e.g. 60s or 2m",
          "description": "For videos only: stop analyzing at this timestamp. Use with startOffset to analyze only a segment (e.g. 30s to 2m). Saves tokens on long videos."
        },
        {
          "name": "mediaResolution",
          "label": "Resolution (optional)",
          "type": "select",
          "options": [
            {
              "value": "low",
              "label": "Low (fewer tokens, good for long videos)"
            },
            {
              "value": "medium",
              "label": "Medium (balanced)"
            },
            {
              "value": "high",
              "label": "High (more detail, more tokens)"
            }
          ],
          "description": "Media resolution affects token usage. Low = ~100 tokens/sec, High = ~300 tokens/sec."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/digestAssetInput",
        "definitions": {
          "digestAssetInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "query": {
                "type": "string"
              },
              "depth": {
                "type": "string",
                "enum": [
                  "quick",
                  "detailed",
                  "exhaustive"
                ],
                "default": "detailed"
              },
              "startOffset": {
                "type": "string"
              },
              "endOffset": {
                "type": "string"
              },
              "mediaResolution": {
                "type": "string",
                "enum": [
                  "low",
                  "medium",
                  "high"
                ]
              }
            },
            "required": [
              "assetId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "watchAsset": {
      "name": "watchAsset",
      "label": "Watch Asset",
      "description": "Load an asset (video, image, or audio) so you can see/hear it directly. Use startTime/endTime (in seconds) to focus on a specific segment of video. Use this when you need to analyze media with conversation context, compare to discussed styles, answer follow-up questions, or when the user wants you to 'look at' or 'watch' something.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. asset_abc123",
          "description": "The ID of the asset to watch/view.",
          "required": true
        },
        {
          "name": "startTime",
          "label": "Start Time",
          "type": "text",
          "placeholder": "e.g. 2.5",
          "description": "Optional start time in seconds for video segment.",
          "required": false
        },
        {
          "name": "endTime",
          "label": "End Time",
          "type": "text",
          "placeholder": "e.g. 10",
          "description": "Optional end time in seconds for video segment.",
          "required": false
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/watchAssetInput",
        "definitions": {
          "watchAssetInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "startTime": {
                "type": "string",
                "description": "Start time in seconds (e.g. '2.5' or '10') to view a specific segment"
              },
              "endTime": {
                "type": "string",
                "description": "End time in seconds (e.g. '5.0' or '15') to view a specific segment"
              }
            },
            "required": [
              "assetId"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "watchVideo": {
      "name": "watchVideo",
      "label": "Watch Video",
      "description": "Render a preview of the current timeline and watch it. Optionally use startTime and endTime (seconds) to render only a segment. Triggers a fast low-resolution render (360p @ 10fps), waits for completion, then returns the video so you can see it directly. Use to review your edits. Takes 10-60 seconds.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "startTime",
          "label": "Start Time (s)",
          "type": "number",
          "placeholder": "e.g. 5",
          "description": "Optional start time in seconds to watch only part of the timeline.",
          "required": false
        },
        {
          "name": "endTime",
          "label": "End Time (s)",
          "type": "number",
          "placeholder": "e.g. 15",
          "description": "Optional end time in seconds (use with startTime).",
          "required": false
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/watchVideoInput",
        "definitions": {
          "watchVideoInput": {
            "type": "object",
            "properties": {
              "startTime": {
                "type": "number",
                "minimum": 0,
                "description": "Start time in seconds to render only a segment (use with endTime)."
              },
              "endTime": {
                "type": "number",
                "minimum": 0,
                "description": "End time in seconds to render only a segment (use with startTime)."
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "applyVideoEffectToClip": {
      "name": "applyVideoEffectToClip",
      "label": "Apply Video Effect to Clip",
      "description": "Apply a video effect (e.g. segmentation) to a clip/asset. Before using: digest the clip (digestAsset or getAssetMetadata) to understand the video content and choose where to place tracking points (click coordinates and frames) for the segmentation effect.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "applyVideoEffectToClip"
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. asset_abc123",
          "required": true,
          "description": "The asset (clip) to apply the effect to."
        },
        {
          "name": "effectId",
          "label": "Effect",
          "type": "text",
          "placeholder": "replicate.meta.sam2-video",
          "defaultValue": "replicate.meta.sam2-video",
          "description": "Effect ID; default is segmentation (SAM-2)."
        },
        {
          "name": "clickCoordinates",
          "label": "Click Coordinates",
          "type": "textarea",
          "placeholder": "[391,239],[178,320]",
          "required": true,
          "description": "Tracking points as [x,y] pairs. Digest the clip first to choose where to click."
        },
        {
          "name": "clickFrames",
          "label": "Click Frames",
          "type": "text",
          "placeholder": "1,15,30",
          "defaultValue": "1",
          "description": "Frame numbers where clicks apply (comma-separated)."
        },
        {
          "name": "clickObjectIds",
          "label": "Click Object IDs (optional)",
          "type": "text",
          "placeholder": "bee_1,bee_2"
        },
        {
          "name": "maskType",
          "label": "Mask Type",
          "type": "select",
          "options": [
            {
              "value": "binary",
              "label": "Binary mask"
            },
            {
              "value": "highlighted",
              "label": "Highlight objects"
            }
          ],
          "defaultValue": "binary"
        },
        {
          "name": "videoFps",
          "label": "Output FPS",
          "type": "number",
          "defaultValue": "25",
          "description": "Frames per second for output (1–60)."
        },
        {
          "name": "outputVideo",
          "label": "Return Video",
          "type": "select",
          "options": [
            {
              "value": "true",
              "label": "Yes"
            },
            {
              "value": "false",
              "label": "No"
            }
          ],
          "defaultValue": "true"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/applyVideoEffectToClipInput",
        "definitions": {
          "applyVideoEffectToClipInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "effectId": {
                "type": "string",
                "minLength": 1,
                "default": "replicate.meta.sam2-video",
                "description": "Effect to apply; default is segmentation (SAM-2)"
              },
              "clickCoordinates": {
                "type": "string",
                "description": "Tracking points as [x,y] pairs, e.g. '[391,239],[178,320]'. Digest the clip first to choose coordinates."
              },
              "clickFrames": {
                "type": "string",
                "default": "1",
                "description": "Comma-separated frame numbers where clicks apply, e.g. '1,15,30'"
              },
              "clickObjectIds": {
                "type": "string",
                "default": ""
              },
              "maskType": {
                "type": "string",
                "enum": [
                  "binary",
                  "highlighted"
                ],
                "default": "binary"
              },
              "videoFps": {
                "type": "integer",
                "minimum": 1,
                "maximum": 60,
                "default": 25
              },
              "outputVideo": {
                "type": "boolean",
                "default": true
              }
            },
            "required": [
              "assetId",
              "clickCoordinates"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "searchAssets": {
      "name": "searchAssets",
      "label": "Search Assets",
      "description": "Search for assets by content - filename, AI description, transcripts, detected labels, and Gemini analysis. Use when the user asks to 'find' or 'search' for specific content.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "query",
          "label": "Search Query",
          "type": "text",
          "placeholder": "sunset beach, person speaking, logo...",
          "description": "Natural language search query",
          "required": true
        },
        {
          "name": "type",
          "label": "Asset Type",
          "type": "select",
          "options": [
            {
              "value": "",
              "label": "All types"
            },
            {
              "value": "video",
              "label": "Video"
            },
            {
              "value": "audio",
              "label": "Audio"
            },
            {
              "value": "image",
              "label": "Image"
            }
          ],
          "description": "Filter by asset type"
        },
        {
          "name": "limit",
          "label": "Max Results",
          "type": "number",
          "placeholder": "10",
          "description": "Maximum number of results (1-50)"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/searchAssetsInput",
        "definitions": {
          "searchAssetsInput": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string",
                "minLength": 1,
                "description": "Search query - can be natural language like 'sunset beach' or 'person talking'"
              },
              "type": {
                "type": "string",
                "enum": [
                  "all",
                  "video",
                  "audio",
                  "image",
                  "other"
                ],
                "description": "Filter by asset type"
              },
              "limit": {
                "type": "number",
                "minimum": 1,
                "maximum": 50,
                "default": 10,
                "description": "Maximum number of results"
              }
            },
            "required": [
              "query"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "setAssetNotes": {
      "name": "setAssetNotes",
      "label": "Set Asset Notes",
      "description": "Set or update notes on an asset to remember what it is for (e.g. B-roll for intro, voiceover take 2). Use empty notes to clear.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "setAssetNotes"
      },
      "fields": [
        {
          "name": "assetId",
          "label": "Asset ID",
          "type": "text",
          "placeholder": "e.g. uuid of the asset",
          "required": true
        },
        {
          "name": "notes",
          "label": "Notes",
          "type": "textarea",
          "placeholder": "What is this asset for?"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/setAssetNotesInput",
        "definitions": {
          "setAssetNotesInput": {
            "type": "object",
            "properties": {
              "assetId": {
                "type": "string",
                "minLength": 1
              },
              "notes": {
                "type": "string"
              }
            },
            "required": [
              "assetId",
              "notes"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "setSceneConfig": {
      "name": "setSceneConfig",
      "label": "Set Scene Config",
      "description": "Set the project scene configuration: dimensions (width x height), frame rate (fps), background color, or project name. Only provided fields are updated.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "setSceneConfig"
      },
      "fields": [
        {
          "name": "width",
          "label": "Width",
          "type": "number",
          "description": "Output width in pixels (min 320). Use with height to set resolution."
        },
        {
          "name": "height",
          "label": "Height",
          "type": "number",
          "description": "Output height in pixels (min 240). Use with width to set resolution."
        },
        {
          "name": "fps",
          "label": "FPS",
          "type": "number",
          "description": "Frames per second (1–240). Common values: 24, 25, 30, 50, 60."
        },
        {
          "name": "background",
          "label": "Background",
          "type": "text",
          "placeholder": "#000000",
          "description": "Background color as hex (e.g. #000000 for black)."
        },
        {
          "name": "name",
          "label": "Project Name",
          "type": "text",
          "description": "Project display name."
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/setSceneConfigInput",
        "definitions": {
          "setSceneConfigInput": {
            "type": "object",
            "properties": {
              "width": {
                "type": "integer",
                "minimum": 320
              },
              "height": {
                "type": "integer",
                "minimum": 240
              },
              "fps": {
                "type": "integer",
                "minimum": 1,
                "maximum": 240
              },
              "background": {
                "type": "string"
              },
              "name": {
                "type": "string"
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "applyChromaKeyToClip": {
      "name": "applyChromaKeyToClip",
      "label": "Apply Chroma Key to Clip",
      "description": "Apply a chroma key (green screen) effect to a video or image clip. Makes the chosen key color transparent so you can composite over another background. Use getTimelineState to find clip IDs.",
      "runLocation": "client",
      "implementations": {
        "app": true,
        "langgraph": true,
        "langgraphName": "applyChromaKeyToClip"
      },
      "fields": [
        {
          "name": "clipId",
          "label": "Clip ID",
          "type": "text",
          "required": true,
          "description": "ID of the video or image clip to key"
        },
        {
          "name": "color",
          "label": "Key color",
          "type": "text",
          "placeholder": "#00ff00",
          "required": true,
          "description": "Hex color to make transparent (e.g. #00ff00 green, #0000ff blue)"
        },
        {
          "name": "threshold",
          "label": "Threshold",
          "type": "number",
          "placeholder": "0.4",
          "description": "0–1: higher = more of the key color becomes transparent (default 0.4)"
        },
        {
          "name": "smoothness",
          "label": "Smoothness",
          "type": "number",
          "placeholder": "0.1",
          "description": "0–1: edge softness (default 0.1)"
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/applyChromaKeyToClipInput",
        "definitions": {
          "applyChromaKeyToClipInput": {
            "type": "object",
            "properties": {
              "clipId": {
                "type": "string",
                "minLength": 1
              },
              "color": {
                "type": "string",
                "pattern": "^#[0-9a-fA-F]{3,6}$",
                "description": "Key color to make transparent (hex)"
              },
              "threshold": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "default": 0.4,
                "description": "Tolerance 0–1: higher = more pixels become transparent"
              },
              "smoothness": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "default": 0.1,
                "description": "Edge softness 0–1 (optional)"
              }
            },
            "required": [
              "clipId",
              "color"
            ],
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "sleep": {
      "name": "sleep",
      "label": "Sleep",
      "description": "Wait for a specified number of seconds.",
      "runLocation": "server",
      "implementations": {
        "app": true,
        "langgraph": false
      },
      "fields": [
        {
          "name": "seconds",
          "label": "Seconds",
          "type": "number",
          "placeholder": "5",
          "description": "How long to wait (1-25 seconds).",
          "required": true
        }
      ],
      "inputSchema": {
        "$ref": "#/definitions/sleepInput",
        "definitions": {
          "sleepInput": {
            "type": "object",
            "properties": {
              "seconds": {
                "type": "integer",
                "minimum": 1,
                "maximum": 25,
                "default": 5
              }
            },
            "additionalProperties": false
          }
        },
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    },
    "listProjectAssets": {
      "name": "listProjectAssets",
      "label": "List Project Assets",
      "description": "List all assets associated with a specific project.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "listProjectAssets"
      },
      "fields": [],
      "inputSchema": null
    },
    "renderVideo": {
      "name": "renderVideo",
      "label": "Render Video",
      "description": "Trigger a video render job for the current project.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "renderVideo"
      },
      "fields": [],
      "inputSchema": null
    },
    "getVideoEffectJobStatus": {
      "name": "getVideoEffectJobStatus",
      "label": "Check Video Effect Job Status",
      "description": "Check the status of a video effect job started by applyVideoEffectToClip.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "getVideoEffectJobStatus"
      },
      "fields": [],
      "inputSchema": null
    },
    "removeBackgroundOnImage": {
      "name": "removeBackgroundOnImage",
      "label": "Remove Background from Image",
      "description": "Remove the background from an image. Polls until done, then returns the result. Use asset_id for project assets or image_url for external URLs.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "removeBackgroundOnImage"
      },
      "fields": [],
      "inputSchema": null
    },
    "reorderLayers": {
      "name": "reorderLayers",
      "label": "Reorder Timeline Layers",
      "description": "Reorder timeline layers (first = bottom, last = top). Use when the user says the title should be on top or layers are reversed.",
      "runLocation": "server",
      "implementations": {
        "app": false,
        "langgraph": true,
        "langgraphName": "reorderLayers"
      },
      "fields": [],
      "inputSchema": null
    }
  }
}